{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6482c582",
   "metadata": {},
   "source": [
    "# Model Training and Validation\n",
    "\n",
    "This notebook demonstrates training and validation of various machine learning models for soil health prediction.\n",
    "\n",
    "## Objectives:\n",
    "- Train SVM, ANN, and clustering models\n",
    "- Compare model performance\n",
    "- Optimize hyperparameters\n",
    "- Evaluate results comprehensively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381ab6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../src')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Import custom modules\n",
    "from models.svm_model import SoilHealthSVM\n",
    "from models.ann_model import SoilHealthANN\n",
    "from models.clustering_model import SoilHealthClustering, compare_clustering_algorithms\n",
    "from evaluation import ModelEvaluator, ModelComparison, feature_importance_analysis\n",
    "from data_preprocessing import SoilDataPreprocessor\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08713ee",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a57476b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data_path = '../data/soil_health_dataset.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {list(df.columns)}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa523d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize preprocessor and preprocess data\n",
    "preprocessor = SoilDataPreprocessor()\n",
    "df_processed = preprocessor.fit_transform(df)\n",
    "\n",
    "print(f\"Processed dataset shape: {df_processed.shape}\")\n",
    "print(f\"\\nFeature columns after preprocessing:\")\n",
    "print(list(df_processed.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e5947d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and targets\n",
    "# Exclude non-feature columns\n",
    "exclude_cols = ['field_id', 'measurement_date', 'health_category', 'soil_health_score', 'recommendations']\n",
    "feature_cols = [col for col in df_processed.columns if col not in exclude_cols]\n",
    "\n",
    "X = df_processed[feature_cols]\n",
    "y_classification = df_processed['health_category'] if 'health_category' in df_processed.columns else None\n",
    "y_regression = df_processed['soil_health_score'] if 'soil_health_score' in df_processed.columns else None\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Feature columns: {list(X.columns)}\")\n",
    "\n",
    "if y_classification is not None:\n",
    "    print(f\"\\nClassification target distribution:\")\n",
    "    print(y_classification.value_counts())\n",
    "\n",
    "if y_regression is not None:\n",
    "    print(f\"\\nRegression target statistics:\")\n",
    "    print(y_regression.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0223f60f",
   "metadata": {},
   "source": [
    "## 2. Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dee8bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data for classification and regression tasks\n",
    "test_size = 0.2\n",
    "val_size = 0.2  # 20% of training data for validation\n",
    "\n",
    "if y_classification is not None:\n",
    "    # Classification split\n",
    "    X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(\n",
    "        X, y_classification, test_size=test_size, random_state=42, stratify=y_classification\n",
    "    )\n",
    "    \n",
    "    X_train_class, X_val_class, y_train_class, y_val_class = train_test_split(\n",
    "        X_train_class, y_train_class, test_size=val_size, random_state=42, stratify=y_train_class\n",
    "    )\n",
    "    \n",
    "    print(f\"Classification splits:\")\n",
    "    print(f\"Train: {X_train_class.shape}, Validation: {X_val_class.shape}, Test: {X_test_class.shape}\")\n",
    "\n",
    "if y_regression is not None:\n",
    "    # Regression split\n",
    "    X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "        X, y_regression, test_size=test_size, random_state=42\n",
    "    )\n",
    "    \n",
    "    X_train_reg, X_val_reg, y_train_reg, y_val_reg = train_test_split(\n",
    "        X_train_reg, y_train_reg, test_size=val_size, random_state=42\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nRegression splits:\")\n",
    "    print(f\"Train: {X_train_reg.shape}, Validation: {X_val_reg.shape}, Test: {X_test_reg.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fa16d7",
   "metadata": {},
   "source": [
    "## 3. SVM Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1595325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM Classification\n",
    "if y_classification is not None:\n",
    "    print(\"=== SVM Classification ===\")\n",
    "    \n",
    "    # Initialize SVM classifier\n",
    "    svm_classifier = SoilHealthSVM(task_type='classification')\n",
    "    \n",
    "    # Create and train model\n",
    "    svm_classifier.create_model(kernel='rbf', C=1.0, gamma='scale')\n",
    "    svm_classifier.train(X_train_class, y_train_class)\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    val_results_svm_class = svm_classifier.evaluate(X_val_class, y_val_class)\n",
    "    \n",
    "    # Hyperparameter tuning\n",
    "    print(\"\\nPerforming hyperparameter tuning...\")\n",
    "    best_params_svm_class = svm_classifier.tune_hyperparameters(\n",
    "        X_train_class, y_train_class, cv=3\n",
    "    )\n",
    "    print(f\"Best parameters: {best_params_svm_class}\")\n",
    "    \n",
    "    # Train with best parameters\n",
    "    svm_classifier.create_model(**best_params_svm_class)\n",
    "    svm_classifier.train(X_train_class, y_train_class)\n",
    "    \n",
    "    # Final evaluation\n",
    "    print(\"\\nFinal evaluation on test set:\")\n",
    "    test_results_svm_class = svm_classifier.evaluate(X_test_class, y_test_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dc63cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM Regression\n",
    "if y_regression is not None:\n",
    "    print(\"=== SVM Regression ===\")\n",
    "    \n",
    "    # Initialize SVM regressor\n",
    "    svm_regressor = SoilHealthSVM(task_type='regression')\n",
    "    \n",
    "    # Create and train model\n",
    "    svm_regressor.create_model(kernel='rbf', C=1.0, gamma='scale', epsilon=0.1)\n",
    "    svm_regressor.train(X_train_reg, y_train_reg)\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    val_results_svm_reg = svm_regressor.evaluate(X_val_reg, y_val_reg)\n",
    "    \n",
    "    # Hyperparameter tuning\n",
    "    print(\"\\nPerforming hyperparameter tuning...\")\n",
    "    best_params_svm_reg = svm_regressor.tune_hyperparameters(\n",
    "        X_train_reg, y_train_reg, cv=3\n",
    "    )\n",
    "    print(f\"Best parameters: {best_params_svm_reg}\")\n",
    "    \n",
    "    # Train with best parameters\n",
    "    svm_regressor.create_model(**best_params_svm_reg)\n",
    "    svm_regressor.train(X_train_reg, y_train_reg)\n",
    "    \n",
    "    # Final evaluation\n",
    "    print(\"\\nFinal evaluation on test set:\")\n",
    "    test_results_svm_reg = svm_regressor.evaluate(X_test_reg, y_test_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b81b9f",
   "metadata": {},
   "source": [
    "## 4. ANN Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8efe159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN Classification\n",
    "if y_classification is not None:\n",
    "    print(\"=== ANN Classification ===\")\n",
    "    \n",
    "    # Initialize ANN classifier\n",
    "    ann_classifier = SoilHealthANN(task_type='classification')\n",
    "    \n",
    "    # Train model\n",
    "    history_class = ann_classifier.train(\n",
    "        X_train_class, y_train_class,\n",
    "        X_val_class, y_val_class,\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Plot training history\n",
    "    ann_classifier.plot_training_history()\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    print(\"\\nFinal evaluation on test set:\")\n",
    "    test_results_ann_class = ann_classifier.evaluate(X_test_class, y_test_class)\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    ann_classifier.plot_confusion_matrix(X_test_class, y_test_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e90f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN Regression\n",
    "if y_regression is not None:\n",
    "    print(\"=== ANN Regression ===\")\n",
    "    \n",
    "    # Initialize ANN regressor\n",
    "    ann_regressor = SoilHealthANN(task_type='regression')\n",
    "    \n",
    "    # Train model\n",
    "    history_reg = ann_regressor.train(\n",
    "        X_train_reg, y_train_reg,\n",
    "        X_val_reg, y_val_reg,\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Plot training history\n",
    "    ann_regressor.plot_training_history()\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    print(\"\\nFinal evaluation on test set:\")\n",
    "    test_results_ann_reg = ann_regressor.evaluate(X_test_reg, y_test_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042666ba",
   "metadata": {},
   "source": [
    "## 5. Clustering Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d533f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different clustering algorithms\n",
    "print(\"=== Clustering Analysis ===\")\n",
    "\n",
    "# Use full dataset for clustering\n",
    "clustering_results = compare_clustering_algorithms(\n",
    "    X.values, list(X.columns), n_clusters=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a71e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed K-Means analysis\n",
    "print(\"\\n=== Detailed K-Means Analysis ===\")\n",
    "\n",
    "kmeans_clusterer = SoilHealthClustering(algorithm='kmeans')\n",
    "\n",
    "# Find optimal number of clusters\n",
    "kmeans_clusterer.find_optimal_clusters(X.values, max_clusters=8, method='silhouette')\n",
    "\n",
    "# Fit final model with optimal clusters\n",
    "kmeans_clusterer.create_model(n_clusters=4)\n",
    "cluster_labels = kmeans_clusterer.fit(X.values, list(X.columns))\n",
    "\n",
    "# Analyze clusters\n",
    "cluster_stats = kmeans_clusterer.analyze_clusters(X.values, list(X.columns))\n",
    "\n",
    "# 3D visualization\n",
    "kmeans_clusterer.plot_clusters_3d()\n",
    "\n",
    "# Add cluster labels to original data\n",
    "df_with_clusters = df.copy()\n",
    "df_with_clusters['Cluster'] = cluster_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214eebec",
   "metadata": {},
   "source": [
    "## 6. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32472268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare classification models\n",
    "if y_classification is not None:\n",
    "    print(\"=== Classification Model Comparison ===\")\n",
    "    \n",
    "    comparison_class = ModelComparison()\n",
    "    comparison_class.add_model('SVM', svm_classifier.model, 'classification')\n",
    "    comparison_class.add_model('ANN', ann_classifier.model, 'classification')\n",
    "    \n",
    "    class_comparison_results = comparison_class.compare_models(X_test_class, y_test_class)\n",
    "    print(\"\\nClassification Comparison Results:\")\n",
    "    print(class_comparison_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bcd755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare regression models\n",
    "if y_regression is not None:\n",
    "    print(\"=== Regression Model Comparison ===\")\n",
    "    \n",
    "    comparison_reg = ModelComparison()\n",
    "    comparison_reg.add_model('SVM', svm_regressor.model, 'regression')\n",
    "    comparison_reg.add_model('ANN', ann_regressor.model, 'regression')\n",
    "    \n",
    "    reg_comparison_results = comparison_reg.compare_models(X_test_reg, y_test_reg)\n",
    "    print(\"\\nRegression Comparison Results:\")\n",
    "    print(reg_comparison_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c55d5c7",
   "metadata": {},
   "source": [
    "## 7. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4978cf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance analysis\n",
    "print(\"=== Feature Importance Analysis ===\")\n",
    "\n",
    "# Train a Random Forest for feature importance comparison\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "\n",
    "if y_classification is not None:\n",
    "    # Classification feature importance\n",
    "    rf_class = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf_class.fit(X_train_class, y_train_class)\n",
    "    \n",
    "    print(\"\\nClassification Feature Importance:\")\n",
    "    class_importance = feature_importance_analysis(\n",
    "        rf_class, list(X.columns), X_test_class, y_test_class, method='auto'\n",
    "    )\n",
    "\n",
    "if y_regression is not None:\n",
    "    # Regression feature importance\n",
    "    rf_reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    rf_reg.fit(X_train_reg, y_train_reg)\n",
    "    \n",
    "    print(\"\\nRegression Feature Importance:\")\n",
    "    reg_importance = feature_importance_analysis(\n",
    "        rf_reg, list(X.columns), X_test_reg, y_test_reg, method='auto'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c905a3",
   "metadata": {},
   "source": [
    "## 8. Cross-Validation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d196a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation for best models\n",
    "print(\"=== Cross-Validation Analysis ===\")\n",
    "\n",
    "if y_classification is not None:\n",
    "    print(\"\\nSVM Classification Cross-Validation:\")\n",
    "    svm_class_evaluator = ModelEvaluator(svm_classifier.model, \"SVM Classifier\")\n",
    "    svm_class_cv = svm_class_evaluator.cross_validate(X_train_class, y_train_class, cv=5)\n",
    "    \n",
    "    print(\"\\nANN Classification Cross-Validation:\")\n",
    "    # Note: For neural networks, we'll use a simpler approach\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    \n",
    "    mlp_class = MLPClassifier(hidden_layer_sizes=(128, 64, 32), max_iter=500, random_state=42)\n",
    "    ann_class_cv_scores = cross_val_score(mlp_class, X_train_class, y_train_class, cv=5, scoring='accuracy')\n",
    "    print(f\"ANN CV Accuracy: {ann_class_cv_scores.mean():.4f} (+/- {ann_class_cv_scores.std() * 2:.4f})\")\n",
    "\n",
    "if y_regression is not None:\n",
    "    print(\"\\nSVM Regression Cross-Validation:\")\n",
    "    svm_reg_evaluator = ModelEvaluator(svm_regressor.model, \"SVM Regressor\")\n",
    "    svm_reg_cv = svm_reg_evaluator.cross_validate(X_train_reg, y_train_reg, cv=5)\n",
    "    \n",
    "    print(\"\\nANN Regression Cross-Validation:\")\n",
    "    from sklearn.neural_network import MLPRegressor\n",
    "    \n",
    "    mlp_reg = MLPRegressor(hidden_layer_sizes=(128, 64, 32), max_iter=500, random_state=42)\n",
    "    ann_reg_cv_scores = cross_val_score(mlp_reg, X_train_reg, y_train_reg, cv=5, scoring='neg_mean_squared_error')\n",
    "    print(f\"ANN CV RMSE: {np.sqrt(-ann_reg_cv_scores.mean()):.4f} (+/- {np.sqrt(ann_reg_cv_scores.std() * 2):.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fe403e",
   "metadata": {},
   "source": [
    "## 9. Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469bf876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot learning curves for best models\n",
    "print(\"=== Learning Curves ===\")\n",
    "\n",
    "if y_classification is not None:\n",
    "    print(\"\\nSVM Classification Learning Curve:\")\n",
    "    svm_class_evaluator.plot_learning_curve(X_train_class, y_train_class)\n",
    "\n",
    "if y_regression is not None:\n",
    "    print(\"\\nSVM Regression Learning Curve:\")\n",
    "    svm_reg_evaluator.plot_learning_curve(X_train_reg, y_train_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2812c30",
   "metadata": {},
   "source": [
    "## 10. Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f443e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained models\n",
    "import os\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "print(\"=== Saving Models ===\")\n",
    "\n",
    "if y_classification is not None:\n",
    "    # Save classification models\n",
    "    svm_classifier.save_model('../models/svm_classifier')\n",
    "    ann_classifier.save_model('../models/ann_classifier')\n",
    "    print(\"Classification models saved.\")\n",
    "\n",
    "if y_regression is not None:\n",
    "    # Save regression models\n",
    "    svm_regressor.save_model('../models/svm_regressor')\n",
    "    ann_regressor.save_model('../models/ann_regressor')\n",
    "    print(\"Regression models saved.\")\n",
    "\n",
    "# Save preprocessing pipeline\n",
    "import joblib\n",
    "joblib.dump(preprocessor, '../models/preprocessor.pkl')\n",
    "print(\"Preprocessor saved.\")\n",
    "\n",
    "print(\"\\nAll models saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdc9ebc",
   "metadata": {},
   "source": [
    "## 11. Summary and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c147a149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of results\n",
    "print(\"=== TRAINING SUMMARY ===\")\n",
    "print()\n",
    "\n",
    "if y_classification is not None:\n",
    "    print(\"CLASSIFICATION RESULTS:\")\n",
    "    print(f\"SVM Test Accuracy: {test_results_svm_class.get('accuracy', 'N/A'):.4f}\")\n",
    "    print(f\"ANN Test Accuracy: {test_results_ann_class.get('accuracy', 'N/A'):.4f}\")\n",
    "    print()\n",
    "\n",
    "if y_regression is not None:\n",
    "    print(\"REGRESSION RESULTS:\")\n",
    "    print(f\"SVM Test RMSE: {test_results_svm_reg.get('rmse', 'N/A'):.4f}\")\n",
    "    print(f\"SVM Test R²: {test_results_svm_reg.get('r2_score', 'N/A'):.4f}\")\n",
    "    print(f\"ANN Test RMSE: {test_results_ann_reg.get('rmse', 'N/A'):.4f}\")\n",
    "    print(f\"ANN Test R²: {test_results_ann_reg.get('r2_score', 'N/A'):.4f}\")\n",
    "    print()\n",
    "\n",
    "print(\"CLUSTERING RESULTS:\")\n",
    "for algorithm, metrics in clustering_results.items():\n",
    "    print(f\"{algorithm.upper()}: Silhouette Score = {metrics.get('silhouette_score', 'N/A'):.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TRAINING COMPLETED SUCCESSFULLY!\")\n",
    "print(\"All models have been trained, evaluated, and saved.\")\n",
    "print(\"=\"*50)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
